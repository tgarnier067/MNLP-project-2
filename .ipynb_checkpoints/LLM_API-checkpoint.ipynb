{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa041754-9254-4c30-aad7-903428907155",
   "metadata": {},
   "source": [
    "# Gemini : it works !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd232a94-1771-441b-9fb5-e3833548be6d",
   "metadata": {},
   "source": [
    "Link to the documentation : https://ai.google.dev/gemini-api/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984d5817-5dd5-4014-b6a2-a048fb2cdb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44495a57-8257-4c23-9f7b-e2a25d7634a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning patterns from data to make predictions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "# Use the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")  # or \"gemini-1.5-pro\"\n",
    "\n",
    "response = model.generate_content(\"Explain how AI works in a few words\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a882fd0-0313-4018-b20a-4fd511f1714a",
   "metadata": {},
   "source": [
    "# GPT : Does not work for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86795e-1798-47e5-9f4b-c53ee82e7ed2",
   "metadata": {},
   "source": [
    "Link to the documentation : https://platform.openai.com/docs/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7c5315-9408-4d22-b184-eb65a4aff481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 1.81.0\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.12/site-packages (1.81.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y openai\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a27bbe5b-336a-43c2-bdf7-87f67621a1dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.12/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Enter the API key\u001b[39;00m\n\u001b[32m      4\u001b[39m client = OpenAI(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.12/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Enter the API key\n",
    "client = OpenAI('')\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1332b7-4422-4c21-9fd1-7a522ffdf435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade openai --quiet\n",
    "!pip install openai==0.28 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b282b96f-380f-48ef-af49-ceb7a92ad82e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m openai.api_key = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Call the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a one-sentence bedtime story about a unicorn.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m'\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/openai/api_resources/chat_completion.py:25\u001b[39m, in \u001b[36mChatCompletion.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time.time() > start + timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[39m, in \u001b[36mEngineAPIResource.create\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m     **params,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     (\n\u001b[32m    139\u001b[39m         deployment_id,\n\u001b[32m    140\u001b[39m         engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         api_key, api_base, api_type, api_version, organization, **params\n\u001b[32m    151\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     response, _, api_key = \u001b[43mrequestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[32m    165\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/openai/api_requestor.py:298\u001b[39m, in \u001b[36mAPIRequestor.request\u001b[39m\u001b[34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     method,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    287\u001b[39m ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    288\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.request_raw(\n\u001b[32m    289\u001b[39m         method.lower(),\n\u001b[32m    290\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         request_timeout=request_timeout,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     resp, got_stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m.api_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/openai/api_requestor.py:700\u001b[39m, in \u001b[36mAPIRequestor._interpret_response\u001b[39m\u001b[34m(self, result, stream)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    693\u001b[39m         \u001b[38;5;28mself\u001b[39m._interpret_response_line(\n\u001b[32m    694\u001b[39m             line, result.status_code, result.headers, stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    695\u001b[39m         )\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result.iter_lines())\n\u001b[32m    697\u001b[39m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    706\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/openai/api_requestor.py:765\u001b[39m, in \u001b[36mAPIRequestor._interpret_response_line\u001b[39m\u001b[34m(self, rbody, rcode, rheaders, stream)\u001b[39m\n\u001b[32m    763\u001b[39m stream_error = stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp.data\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= rcode < \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle_error_response(\n\u001b[32m    766\u001b[39m         rbody, rcode, resp.data, rheaders, stream_error=stream_error\n\u001b[32m    767\u001b[39m     )\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[31mAuthenticationError\u001b[39m: You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = ''\n",
    "\n",
    "# Call the model\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a one-sentence bedtime story about a unicorn.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2eb3f0-bdf5-482d-b784-5edfef24206e",
   "metadata": {},
   "source": [
    "# Claude : Have to pay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847972b-d1f8-4780-917c-e87c27d650b2",
   "metadata": {},
   "source": [
    "Link to the documentation : https://docs.anthropic.com/en/home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6004372-16eb-4103-85e0-b607d70c4d80",
   "metadata": {},
   "source": [
    "Problem : No access to credit. Without credit, we can not use the models, and we have to pay for credits. I don't succeed to have first free credits on the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e48971b2-7a1d-4f94-a6b7-f11144344981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv claude-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d48d528b-227b-4533-a0bf-18d7349e7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install anthropic --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb74f997-99a4-442a-b84b-1a86c2233bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export ANTHROPIC_API_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d0097c9-3474-49ff-8f8a-6d1dca33c75b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Enter the API key here\u001b[39;00m\n\u001b[32m      4\u001b[39m client = anthropic.Anthropic(api_key=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m message = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-7-sonnet-20250219\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a world-class poet. Respond only with short poems.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhy is the ocean salty?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/anthropic/_utils/_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/anthropic/resources/messages/messages.py:954\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    948\u001b[39m     warnings.warn(\n\u001b[32m    949\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    950\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    951\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    952\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/anthropic/_base_client.py:1290\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1278\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1285\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1286\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1287\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1288\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1289\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/anthropic/_base_client.py:1009\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m   1008\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m   1012\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/anthropic/_base_client.py:505\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n\u001b[32m    507\u001b[39m content_type = headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/anthropic/_base_client.py:446\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    436\u001b[39m custom_headers = options.headers \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    437\u001b[39m headers_dict = _merge_mappings(\n\u001b[32m    438\u001b[39m     {\n\u001b[32m    439\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m     custom_headers,\n\u001b[32m    445\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n\u001b[32m    449\u001b[39m headers = httpx.Headers(headers_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/anthropic/_client.py:196\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers.get(\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m), Omit):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    198\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "# Enter the API key here\n",
    "client = anthropic.Anthropic(api_key='')\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens=1000,\n",
    "    temperature=1,\n",
    "    system=\"You are a world-class poet. Respond only with short poems.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Why is the ocean salty?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48906d2-7cd2-49f6-a72e-9631f509c462",
   "metadata": {},
   "source": [
    "# Qwen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e42f59f-1b60-4885-9547-ed914417e986",
   "metadata": {},
   "source": [
    "Link to the documentation : https://www.alibabacloud.com/help/en/model-studio/first-api-call-to-qwen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66311707-acfd-4f24-8dbe-35ee8725c42e",
   "metadata": {},
   "source": [
    "Problem : No access to credit. Without credit, we can not use the models, and we have to pay for credits. I don't succeed to have first free credits on the site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125d13c-4704-45c4-9263-9a2b4862991c",
   "metadata": {},
   "source": [
    "# HuggingFace : It works !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb16427-3c9d-46a4-923a-977c9b825227",
   "metadata": {},
   "source": [
    "Link to the documentation : https://huggingface.co/docs/inference-providers/index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100a06f-22b7-4944-8af6-48365f4b6f40",
   "metadata": {},
   "source": [
    "**CAUTION** : The credits are limited, we shall not run again and again the code, just to see if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f2a9f-baa3-4294-a8ff-74a2c53cc586",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9283a186-557d-491b-807e-e7506aca834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Invalid credentials in Authorization header'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://router.huggingface.co/novita/v3/openai/chat/completions\"\n",
    "headers = {\"Authorization\": \"Bearer hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How many 'G's in 'huggingface'?\"\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"deepseek/deepseek-v3-0324\",\n",
    "}\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, json=payload)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbb6442a-b800-4b62-9d06-3204f2e6bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e20eb27d-cfce-4e4f-87c4-03cddba56f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutputMessage(role='assistant', content='Alright, let\\'s tackle the problem: **How many \\'G\\'s are in the word \\'huggingface\\'?**\\n\\n### Understanding the Problem\\nFirst, I need to determine how many times the letter \\'G\\' (both uppercase and lowercase, though in this case, the word is all lowercase) appears in the word \"huggingface.\" \\n\\n### Breaking Down the Word\\nLet\\'s write out the word and look at each letter one by one:\\n\\nThe word is: h u g g i n g f a c e\\n\\nNow, let\\'s list the positions and the letters:\\n\\n1. h\\n2. u\\n3. g\\n4. g\\n5. i\\n6. n\\n7. g\\n8. f\\n9. a\\n10. c\\n11. e\\n\\n### Counting the \\'G\\'s\\nNow, let\\'s go through each letter and count how many times \\'g\\' appears:\\n\\n1. h - not g\\n2. u - not g\\n3. g - yes (count = 1)\\n4. g - yes (count = 2)\\n5. i - not g\\n6. n - not g\\n7. g - yes (count = 3)\\n8. f - not g\\n9. a - not g\\n10. c - not g\\n11. e - not g\\n\\n### Verifying\\nLet me recount to ensure I didn\\'t miss anything:\\n\\n- First \\'g\\' at position 3\\n- Second \\'g\\' at position 4\\n- Third \\'g\\' at position 7\\n\\nNo other \\'g\\'s are present in the word.\\n\\n### Potential Pitfalls\\nIt\\'s easy to miscount if I rush, especially with consecutive letters. For example, \"gg\" in the middle might make me think there\\'s only one \\'g\\' if I\\'m not careful. But here, \\'g\\' appears twice in a row (\"gg\"), and then another \\'g\\' later, totaling three.\\n\\n### Conclusion\\nAfter carefully examining each letter in \"huggingface,\" I\\'ve found that the letter \\'g\\' appears **three times**.\\n\\n**Final Answer:** There are **3 \\'G\\'s** in \\'huggingface\\'.', tool_call_id=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"novita\",\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-V3-0324\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How many 'G's in 'huggingface'?\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c591fb63-e556-4dd9-a59b-e9e11450f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's tackle the problem: **How many 'G's are in the word 'huggingface'?**\n",
      "\n",
      "### Understanding the Problem\n",
      "First, I need to determine how many times the letter 'G' (both uppercase and lowercase, though in this case, the word is all lowercase) appears in the word \"huggingface.\" \n",
      "\n",
      "### Breaking Down the Word\n",
      "Let's write out the word and look at each letter one by one:\n",
      "\n",
      "The word is: h u g g i n g f a c e\n",
      "\n",
      "Now, let's list the positions and the letters:\n",
      "\n",
      "1. h\n",
      "2. u\n",
      "3. g\n",
      "4. g\n",
      "5. i\n",
      "6. n\n",
      "7. g\n",
      "8. f\n",
      "9. a\n",
      "10. c\n",
      "11. e\n",
      "\n",
      "### Counting the 'G's\n",
      "Now, let's go through each letter and count how many times 'g' appears:\n",
      "\n",
      "1. h - not g\n",
      "2. u - not g\n",
      "3. g - yes (count = 1)\n",
      "4. g - yes (count = 2)\n",
      "5. i - not g\n",
      "6. n - not g\n",
      "7. g - yes (count = 3)\n",
      "8. f - not g\n",
      "9. a - not g\n",
      "10. c - not g\n",
      "11. e - not g\n",
      "\n",
      "### Verifying\n",
      "Let me recount to ensure I didn't miss anything:\n",
      "\n",
      "- First 'g' at position 3\n",
      "- Second 'g' at position 4\n",
      "- Third 'g' at position 7\n",
      "\n",
      "No other 'g's are present in the word.\n",
      "\n",
      "### Potential Pitfalls\n",
      "It's easy to miscount if I rush, especially with consecutive letters. For example, \"gg\" in the middle might make me think there's only one 'g' if I'm not careful. But here, 'g' appears twice in a row (\"gg\"), and then another 'g' later, totaling three.\n",
      "\n",
      "### Conclusion\n",
      "After carefully examining each letter in \"huggingface,\" I've found that the letter 'g' appears **three times**.\n",
      "\n",
      "**Final Answer:** There are **3 'G's** in 'huggingface'.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
