{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tgarnier067/MNLP-project-2/blob/main/02_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are working on sspcloud\n",
    "\n",
    "!pip install spacy --quiet\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import spacy\n",
    "import re\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngG6cCRETRoO",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l2_61Rw7CzvQ"
   },
   "outputs": [],
   "source": [
    "#Path to english data\n",
    "extract_dir = os.path.expanduser(\"~/work/MNLP-project-2/data/eng\")\n",
    "\n",
    "#path to json files\n",
    "clean_path = os.path.join(extract_dir, \"the_vampyre_clean.json\")\n",
    "ocr_path = os.path.join(extract_dir, \"the_vampyre_ocr.json\")\n",
    "\n",
    "#load files\n",
    "with open(clean_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clean_data = json.load(f)\n",
    "\n",
    "with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ocr_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3gEh-A-TdxN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9cR5D1zwRimY"
   },
   "outputs": [],
   "source": [
    "def concat_values_dict(d):\n",
    "    \"\"\"\n",
    "    Concat values of a dict, seperating each element with '\\n'\n",
    "\n",
    "    Args:\n",
    "        d (dict): Dictionnary\n",
    "\n",
    "    Returns:\n",
    "        str: concatenated text\n",
    "    \"\"\"\n",
    "    return '\\n'.join(d.get(str(i), \"\") for i in range(48))\n",
    "\n",
    "clean_data_text = concat_values_dict(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8WgDq5dWNVH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# T5 : Model fine tuned for grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkglRuwXFGCj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## T5-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxXoINVCz_As"
   },
   "source": [
    "We create a function to apply a prompt wich asks to correct the data, to the LLM T5-base, and print the output of this LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrBGLqP7WWKW"
   },
   "outputs": [],
   "source": [
    "# Charge model and tokenizer\n",
    "model_name = \"t5-base\" # We could use also t5-small\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "def correct_text_with_t5(text):\n",
    "    prompt = f\"Fix errors : {text}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=False, padding=False).to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyrHYk7-gnYl",
    "outputId": "63f5a608-bd9e-4cfe-b191-6a00229f9093"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE VAMPYRE;',\n",
       " 'A Tale.',\n",
       " 'By John William Polidori',\n",
       " 'THEsuperstition upon which this taIe iſ founded is very general in the East. Among tho Arabjans itappeors to be common: it did not, however, extend itself to the Greeks until after the establi shment of Christianity; and it has only aſsumed its prosent form since the division af the Latin and Greok churches; at which time, lhe idea becoming prevalent, that a Lcltin body could not corrvpl if buried in their territory, it gradually increosed, and formed lhe subject of many wonderful stories, ſtill extant, of the dead rising from their graves, and feeding uponlhe blood of tho young and beautiful. In the West itspread, with some slight variation, all over Hungary, Poland, Austria, and Lorraine, whoro the helies existed, that vompyresnightly imbi6ed a certain portion of the blood of their victims, who became emaciated, lost their strength, and speedily died of c0nsumptions; whilst these human blood-suckers fattened—and their veins became distend']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the firsts sentences of a noisy sentence\n",
    "noisy_text = ocr_data['0'][:1000]\n",
    "\n",
    "# Build segment, and prompt to correct on each segment\n",
    "segments = noisy_text.split('\\n')\n",
    "\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vd1Ra8_zOBW",
    "outputId": "065cb9c4-3241-44ec-c66e-bf26853c7127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".: THE VAMPYRE; THE VAMPYRE; THE VAMPY\n",
      ": A Tale.\n",
      "Fix errors : By John William Polidori : By John William Polidori :\n",
      ". : Fix: Fix bug fixes : Fix errors : Fix bug fixes\n"
     ]
    }
   ],
   "source": [
    "# Apply the model on a small dataset\n",
    "for i in range(4):\n",
    "  print(correct_text_with_t5(segments[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRFikl1vzo3r"
   },
   "source": [
    "This model makes a lot of problem, as you can see on the transcription displayed on the above cell. We tried to modify the prompt, the lenght of the inputs, and many other parameters, but still, the quality of the output data was too bad. We will not focus on this model, but look at another one instead : vennify/t5-base-grammar-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqqkbdB5FL0j",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## T5-base-grammar-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5-base-grammar-correction is a transformer model finetuned for grammatical errors correction. It's trained on the dataset JFLEG, a corpus made for developing and evaluating grammatical errors correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0Oyi4f1jv-I",
    "outputId": "0c7c2c46-3d2c-48e5-9a95-143c7872b8a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Output:\n",
      " THE VAMPYRE.\n",
      "A Tale.\n",
      "By John William Polidori.\n",
      "The superstition upon which this taIe is founded is very general in the East. It did not, however, extend itself to the Greeks until after the establishment of Christianity; and it has only assumed its prosent form since the division of the Latin and Greok churches; and it gradually increosed, and formed the subject of many wonderful stories, still extant, of the dead rising from their graves, and feeding upon the blood of young and beautiful people. In the West it spread, with some slight variation,\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned grammar correction model\n",
    "model_name = \"vennify/t5-base-grammar-correction\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def correct_text_with_t5(text):\n",
    "    prompt = f\"correct: {text}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test on a small dataset\n",
    "noisy_text = ocr_data['0'][:1000]\n",
    "segments = [s.strip() for s in noisy_text.split('\\n') if s.strip()]\n",
    "\n",
    "corrected_segments = [correct_text_with_t5(seg) for seg in segments]\n",
    "corrected_text = '\\n'.join(corrected_segments)\n",
    "\n",
    "print(\"Corrected Output:\\n\", corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZownBU5yBky"
   },
   "source": [
    "Problem : The output is not completed. So we increase the max_lenghts to 512. Unfortunatly, it's not enough => we have no longer output for very high values of max_lengths, than with max_lenght = 512. We also try to remove early_stopping, but it does not work. So, as the model can not output very long sentences, we apply it many times, on slices of the text.\n",
    "\n",
    "- Instead of : model(sentence 1, sentence 2, sentence 3...)\n",
    "- We do : model(sentence 1) + model(sentence 2) + model(sentence 3) + ...\n",
    "\n",
    "We use spacy to slice into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRlY6fqfwLpb",
    "outputId": "5e0018c6-5d3e-476f-d475-c46c8a88a2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Output:\n",
      " THE VAMPYRE.\n",
      "A Tale.\n",
      "By John William Polidori.\n",
      "THE superstition upon which this theory is founded is very general in the East. It did not, however, extend itself to the Greeks until after the establishment of Christianity; and it has only assumed its prosent form since the division of the Latin and Greok churches; at which time, the idea becoming prevalent, that a Lcltin body could not corrvpl if buried in their territory, gradually increased, and formed the subject of many wonderful stories, still extant, of the dead rising from their graves, and feeding upon the blood of young and beautiful. In the West it spread, with some slight variation, all over Hungary, Poland, Austria, and Lorraine, whoro the helies existed, that vompyresnightly imbi6ed a certain portion of the blood of their victims, who became emaciated, lost their strength, and quickly died of c0nsumptions; while these human blood-suckers fattened—and their veins became distended to such a state of ropletion, as t0\n",
      "In the London Journal, of March, 1732, is a curiovs, and, of course, credible account of a particular case of vampyrifin, which is stated to have been accurred at Madreyga, in Hungary. It appears, that upon an examination of the cornmander-in-chief arid magistrates of tbe place, they positively and unanimously affirmed, that, about five years before, a certairi Heyduke, named Arnold Paul, had bcen beclrd to say, that at Cassovia, ori the fr0ntiers of the Turkish Servio, he had been tormented by a vampyre, but had found a way to rid This precaution, however, did not prevent him from becoming a vampire; sor, about twenty or thirty days after his death and burial, many persons complained of having been tormented by him, and a deposition was made, that four persons had been deprived of life by his attacks. To prevent further mischief, the lnhabitants havjng consulted their Hadagni, took up the body, and found it (as is supposed to be usual in cafes of uampyrism) fresh, and entjrely free from corruption, and emitting at the rnouth, riose, and ears, pure and fIorid blood. Proof having been thus obtained, they resorted to the accustomed remedy. A stake was driven entirely through the bear and body of Arnold Paul, at which he is reported to have cried out dreadfully as he had been olive. This done, they cut of his head, burned his body, and threw his body into his grave. The same measures were adopted with the corses of the other persons who had previously dicked from varnpyrism, lest they should, in their turn, become clgentf upan others who survived them.\n",
      "The universe1 belief js, that a person sucked by a vampyre becomes a vampire himself, and an arid sucks in his turn.\n",
      "Chlef bai1iff.\n",
      "This monstrous rodomontade is he.\n"
     ]
    }
   ],
   "source": [
    "#Load spacy to split into sentences\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load fine-tuned grammar correction model\n",
    "model_name = \"vennify/t5-base-grammar-correction\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "#function to clean the text\n",
    "def correct_text_with_t5(text):\n",
    "    prompt = f\"correct: {text}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=512,\n",
    "        num_beams=4,\n",
    "        early_stopping=False,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "# main function : split by lines, then sentences, and correct\n",
    "def correct_text_by_line_and_sentence(text):\n",
    "    lines = text.split('\\n')\n",
    "    corrected_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            corrected_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        corrected_sentences = [correct_text_with_t5(sentence) for sentence in sentences]\n",
    "        corrected_line = ' '.join(corrected_sentences)\n",
    "        corrected_lines.append(corrected_line)\n",
    "\n",
    "    return '\\n'.join(corrected_lines)\n",
    "\n",
    "#Example with an OCR extract\n",
    "noisy_text = ocr_data['0'][:3000] \n",
    "corrected_text = correct_text_by_line_and_sentence(noisy_text)\n",
    "\n",
    "print(\"Corrected Output:\\n\", corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gzEGKERwopm",
    "outputId": "6f2293c8-d2b6-4c40-cc45-c68d4254cbd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2733"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SV1NDt7w7KT",
    "outputId": "7a663fef-d9d8-49c6-ae24-59f3800f7edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE VAMPYRE;\n",
      "A Tale.\n",
      "By John William Polidori\n",
      "THE superstition upon which this tale is founded is very general in the East. Among the Arabians it appears to be common: it did not, however, extend itself to the Greeks until after the establishment of Christianity; and it has only assumed its present form since the division of the Latin and Greek churches; at which time, the idea becoming prevalent, that a Latin body could not corrupt if buried in their territory, it gradually increased, and formed the subject of many wonderful stories, still extant, of the dead rising from their graves, and feeding upon the blood of the young and beautiful. In the West it spread, with some slight variation, all over Hungary, Poland, Austria, and Lorraine, where the belief existed, that vampyres nightly imbibed a certain portion of the blood of their victims, who became emaciated, lost their strength, and speedily died of consumptions; whilst these human blood-suckers fattened—and their veins became distended to such a state of repletion, as to cause the blood to flow from all the passages of their bodies, and even from the very pores of their skins.\n",
      "In the London Journal, of March, 1732, is a curious, and, of course, credible account of a particular case of vampyrism, which is stated to have occurred at Madreyga, in Hungary. It appears, that upon an examination of the commander-in-chief and magistrates of the place, they positively and unanimously affirmed, that, about five years before, a certain Heyduke, named Arnold Paul, had been heard to say, that, at Cassovia, on the frontiers of the Turkish Servia, he had been tormented by a vampyre, but had found a way to rid himself of the evil, by eating some of the earth out of the vampyre's grave, and rubbing himself with his blood. This precaution, however, did not prevent him from becoming a vampyre himself; for, about twenty or thirty days after his death and burial, many persons complained of having been tormented by him, and a deposition was made, that four persons had been deprived of life by his attacks. To prevent further mischief, the inhabitants having consulted their Hadagni, took up the body, and found it (as is supposed to be usual in cases of vampyrism) fresh, and entirely free from corruption, and emitting at the mouth, nose, and ears, pure and florid blood. Proof having been thus obtained, they resorted to the accustomed remedy. A stake was driven entirely through the heart and body of Arnold Paul, at which he is reported to have cried out as dreadfully as if he had been alive. This done, they cut off his head, burned his body, and threw the ashes into his grave. The same measures were adopted with the corses of those persons who had previously died from vampyrism, lest they should, in their turn, become agents upon others who survived them.\n",
      "The universal belief is, that a person sucked by a vampyre becomes a vampyre himself, and sucks in his turn.\n",
      "Chief bailiff.\n",
      "This monstrous rodomontade is here relat\n"
     ]
    }
   ],
   "source": [
    "print(clean_data_text[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLuogotVwOzz"
   },
   "source": [
    "Problem : the model skip some parts of the text. We input 3000 characters, and it output only 2733. When looking into details at the translation, we see that it skips some sentences. Maybe, if we try to apply the LLM on smaller slices of the text, we won't skip parts. NOw, we slices when there is a '\\n', and when there is a ,:;!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BvZrWGfr5RT",
    "outputId": "b079dd68-179d-4f3d-f9a8-b36505868e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Output:\n",
      " THE VAMPYRE is correct.\n",
      "A Tale.\n",
      "By John William Polidori.\n",
      "THE superstition upon which this theory is founded is very general in the East. Among Arabjans itappeors to be common. It did not. However, this is correct: however, the facts are correct. It extends itself to the Greeks until after the establishment of Christianity. And it has only assumed its prosent form since the division of the Latin and Greok churches. At which time is correct: at which time. The idea is becoming prevalent. That a Lcltin body could not be corrvpl if buried in their territory. It gradually increased. And formed the subject of many wonderful stories. The fact is that there are still a lot of fossils that are still extant. The dead are rising from their graves. And feeding on the blood of tho young and beautiful. In the West it spreads throughout the world. With some slight variation. All over Hungary, Hungary is correct. Poland is correct. Austria is correct. And Lorraine is correct. Whoro the helies existed? Who the hells existed? That vompyresnightly imbi6ed a certain portion of the blood of their victims. Who became emaciated? They lost their strength. And quickly died of c0nsumptions. While these human blood-suckers fattened—and their veins became distended to such a state of ropletion. As t0 cause the blood to flow from all the passages of their badies. And even for the ucry pores of the skin.\n",
      "In theLond0n Journal. The month of March is correct. 1732, correct: 1732. Is a curiovs. Correct: and so on. Of course, of course. Credible account of a particular case of vampyrifin. Which is stated to have been accurred at Madreyga. In Hungary. It appears that it appears to be correct. Upon an examination of the cornmander-in-chief arid magistrates of the place, it is correct that upon examination of these judges, the judge is correct. They positively and unanimously affirmed that. That is correct: that is correct. About five years before that. A certairi Heyduke. Arnold Paul was named Arnold Paul. Had bcen beclrd to say that. That is correct: that is correct. At Cassovia. Or the descendants of the Turkish Servio are correct. He had been tormented by a vampire. But he had found a way to rid himself of the euj1. By eating some of the earth out of the vampyre's grove. And rubbing himself with his blood. This precaution is correct. However, this is correct: however, the facts are correct. Did not prevent him from bccoming a vampyre himsels. Sorrow: sorrow. About twenty or thirty days after his death and burial. Many persons complain of being tortured by him. And a deposition was made. Four persons had been deprived of life by his attacks. To prevent further mischief. The lnhabitants havjng consulted their Hadagni. Correct: took up the body. And f ound it (as is supposed to be usual in cafes of utopia) fresh. And entjrely free from corruption. Correct and emitting at the rearnouth. riose, you are correct. And ears are correct. Pure and healthy blood. Proof having been thus obtained, proof has been obtained. They resorted to the accustomed remedy. A stake was driven entirely through the bear and body of Arnold Paul. At which he is reported to have cried out dreadfully as is he had been olive. This is done. They cut of his head. He burned his body. And threw his asbes into his grave. The same measures were adopted with the cases of the same persons who had previously dicked from varnpyrism. Lest they should be correct. In their turn, they are correct. Become clgentf upan others who survived them.\n",
      "The universe1 belief js. That a person sucked by a vampyre becomes a vampire himself. Arid sucks in his turn.\n",
      "Chlef bai1iff.\n",
      "This monstrous rodomontade is he.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load fine-tuned grammar correction model\n",
    "model_name = \"vennify/t5-base-grammar-correction\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "#Function to clean an input text\n",
    "def correct_text_with_t5(text):\n",
    "    prompt = f\"correct: {text}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=1024,       \n",
    "        num_beams=4,\n",
    "        early_stopping=False, \n",
    "        length_penalty=1.0,   \n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "\n",
    "def split_sentences_and_punct(text):\n",
    "    #Firstly split into sentences\n",
    "    spacy_sents = split_into_sentences_spacy(text)\n",
    "\n",
    "    # then split according to punctuations\n",
    "    punct_split_sents = []\n",
    "    for sent in spacy_sents:\n",
    "        parts = re.split(r'[,:;!?]', sent)\n",
    "        parts = [p.strip() for p in parts if p.strip()]\n",
    "        punct_split_sents.extend(parts)\n",
    "    return punct_split_sents\n",
    "\n",
    "\n",
    "# main function that split into lines, sentences and with punctuations\n",
    "def correct_text_by_line_and_sentence(text):\n",
    "    lines = text.split('\\n')\n",
    "    corrected_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            corrected_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_sentences_and_punct(line)\n",
    "        corrected_sentences = [correct_text_with_t5(sentence) for sentence in sentences]\n",
    "        corrected_line = ' '.join(corrected_sentences)\n",
    "        corrected_lines.append(corrected_line)\n",
    "\n",
    "    return '\\n'.join(corrected_lines)\n",
    "\n",
    "# Example\n",
    "noisy_text = ocr_data['0'][:3000] \n",
    "corrected_text = correct_text_by_line_and_sentence(noisy_text)\n",
    "\n",
    "print(\"Corrected Output:\\n\", corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN3c7h57xGXD"
   },
   "source": [
    "New problems : the time computation starts beeing very high : 3 min to apply on 3000 characters. When we will generalize it to the 48 texts, it's going to take hours. Moreover, the outputs are not correct :    \n",
    "\n",
    "- Noisy : In theLond0n Journal, of March, 1732, is a curiovs, and, of course, credible account of a particular case of vampyrifin, which is stated to hove accurred at Madreyga, in Hungary.\n",
    "\n",
    "- Cleaned : In theLond0n Journal. The month of March is correct. 1732, correct: 1732. Is a curiovs. Correct: and so on. Of course, of course. Credible account of a particular case of vampyrifin. Which is stated to have been accurred at Madreyga. In Hungary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr9m9gA8FthM",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## T5-small-grammar-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAAT-F6-Fyds"
   },
   "source": [
    "This model is a smaller version of T5-base-grammar-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJbW5un6Fx_M",
    "outputId": "2f63ae21-f0cb-4d9e-fb99-4c0e6eadd5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Output:\n",
      " е аее;\n",
      "A Tale.\n",
      "By John William Polidori\n",
      "The superstition upon which this taIe is founded is very general in the East. Among tho Arabjans itappeors to be common: it did not extend itself to the Greeks until after the establi shment of Christianity; and it has only assumed its prosent form since the division af the Latin and Greok churches; at which time, lhe idea becoming prevalent, that a Lcltin body could not corrvpl if buried in their territory, it gradually increosed, and formed a subject of many wonderful stories, still ex In the West itspread, with some slight variation, all over Hungary, Poland, Austria, and Lorraine, whoro the helies existed, that vompyresnightly imbi6ed a certain portion of the blood of their victims, who became emaciated, lost their strength, and speedily died of c0nsumptions; while these human blood-suckers fattened—and their veins became distended to such a state of ropletion, as\n",
      "In theLond0n Journal, of March, 1732, is a curiovs, and, of course, credible account of a particular case of vampyrifin, which is stated to hove accurred at Madreyga, in Hungary. It appears, that upon an examination of the cornmander-in-chief arid magistrates of tbe place, they positively and unanimously affirmed, that, about five years before, a certairi Heyduke, named Arnold Paul, had bcen beclrd to say that, at Cassovia, ori the fr0ntiers of the Turkish Servio, he had been tormented by a vampyre, but had found a way to rid This prccaution, however, did not prevent him from bccoming a vampyre himsels; sor, about twenty or thirty days after his death and burial, many persons complain of being tormented by him, and a deposition was made, that four persons had been deprived os life by his attacks. To prevent further mischief, the lnhabitants havjng consulted their Hadagni, took up the body, and f ound it fresh, and free from corruptjon, and emitting at the rnouth, riose, and ears, pure and iorid blood. The proof having been thus obtained, they resorted to the accustomed remedy. A stake was driven entirely lhrough the bearl and body of Arnold Paul, at which he is reported to hauecried out cls dreadfully as is he had been olive. This done, they cut ofs his head, burned his body, and threw lhe asbes into his grave. The same measures were adopted with the corses of th ose persons who had previously dicd from varnpyrism, so that they should, in their turn, become clgentf upan others who survived them.\n",
      "The universa1 belief js, that a person sucked by a vampyre becomes a self, arid sucks in his turn.\n",
      "I am correct: Chlef bai1iff.\n",
      "This monstrous rodomontade is he\n"
     ]
    }
   ],
   "source": [
    "#Load spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load fine-tuned grammar correction model\n",
    "model_name = \"AventIQ-AI/T5-small-grammar-correction\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "#function to correct input text with the model\n",
    "def correct_text_with_t5(text):\n",
    "    prompt = f\"correct: {text}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=512,\n",
    "        num_beams=4,\n",
    "        early_stopping=False,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "#main function : split into sentences and correct\n",
    "def correct_text_by_line_and_sentence(text):\n",
    "    lines = text.split('\\n')\n",
    "    corrected_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            corrected_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        corrected_sentences = [correct_text_with_t5(sentence) for sentence in sentences]\n",
    "        corrected_line = ' '.join(corrected_sentences)\n",
    "        corrected_lines.append(corrected_line)\n",
    "\n",
    "    return '\\n'.join(corrected_lines)\n",
    "\n",
    "# Example\n",
    "noisy_text = ocr_data['0'][:3000] \n",
    "corrected_text = correct_text_by_line_and_sentence(noisy_text)\n",
    "\n",
    "print(\"Corrected Output:\\n\", corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ3Hy1GjK4Ed"
   },
   "source": [
    "## T5-efficient-tiny-grammar-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa330QVqK9WU"
   },
   "source": [
    "This model is even smaller than T5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "758d86f3da5a4f4696615ac661117fc6",
      "869a497fd6904e3dac2658775a4fc300",
      "9c5b822963d7447b8e3d90179539e6cc",
      "5d174d52d6b845a9baef9c0860d74be1",
      "6d8a9a1135304f9e944bdab7d6fba04a",
      "7fefd84799ba4307b4ccce8a1846d0f2",
      "f317e78b0c1e441b9101e73a54e797d5",
      "f75c0eecb8d7400ab484ebe2cc8d8a40",
      "5a3ff275937b42a9b63e437d3f03d09c",
      "854bda05c93e4b60bfbe31d1f7664901",
      "1dc9395e08924115a31008e083fdfc82",
      "430a11689f0a4510ac090fe2d8469f36",
      "b8be016da8884eb38f5b25bdd4010c44",
      "5058cd3cbc7c4d6e85e91314ae7570fd",
      "0f4b5438fbfb4b858e261aedd1da5e33",
      "d1db3d57963044c390db0f1570b36a97",
      "e6cfe5a720f24e74b380256e093f693a",
      "a99a0747b08e43bd962f56bc5ef66a18",
      "1e91694c48b9406bbffea729d9ecf697",
      "75b1f08a88924475b06d2a3d5e7fdefa",
      "149186b04f4043c4be118317a9695a0a",
      "0cb03469d1bf4c0e8e91204f080cada2",
      "893ce825689a4034906ef2d39070fcb8",
      "275630669fd340b6a0128b170ad02bec",
      "4d3fb41c4ab047e2a375d952476bc034",
      "6164a91d8977420e9387fb0dadd046b0",
      "7e4b5c55eddb42619a85456c93860845",
      "d9bec3116f454401b359626d702418a4",
      "bf50ac8e7dfd448b93d54d2888c0a7b3",
      "36d40324d91e43ec872b25401aa8822e",
      "38881b9982c9478090eabe41edff97e4",
      "858fb9b9d9d944809c8f0388a3dd6f41",
      "568d603575da4b3da7cf30c99d4aad5d",
      "8cc47a551f824308b4d9c75692dc6e41",
      "2bed1e3785a145e5905a60eb362069a3",
      "8f3eebcb29394960b1632612b13afb0a",
      "ad07de60ecde47b294e16573727348be",
      "edbc3129b22a44ca984aa1784550e9f1",
      "1910bfc040714ca8954d3ce7b22fd82d",
      "f067d2b27f6a4a22a3e4c0728c8294fc",
      "152263694a494b92bb8ad9ec81adc271",
      "4132a5fb1b8643448453bcdc06b20dda",
      "0a0a498d233c4493b08a97f21f2f3c7c",
      "7ef659ac5f6d425baf4a63d62868172e",
      "22edbb46aac6430f98e33f0f34095cdc",
      "33e30b12309b4d96bb07ff18719a7720",
      "158e5a60da874d07ab22b621450c89df",
      "254ef13f173c497e9dee2778fd769ea5",
      "7e90feeecf344b40b745a1c78526f182",
      "cff4527568df420f87979f2d7a45e53d",
      "4258214a109246749c32614642536ca6",
      "f4929986efdd46a498d6cafdfbdeb9c7",
      "84246f791e45442498cc3bbc5405005e",
      "f8774e65b9474e3a97bc9846d3b9a278",
      "0dc9932b5679403a8e4bbf1e4270aaae",
      "aeff0f088571441daca0194f5b8a9fac",
      "fee60c131a7e49f89a86a3bbbcbfb291",
      "21803185179049949d9ef7bcfd68a58b",
      "5beeaebb93434e5a8f901d3693ba3712",
      "d1006dc6ccf048ff954a9ca007ca8bb5",
      "d487286961f7461dbeaf72a9942a7da7",
      "8fca437113974322a4d6ce94185596c7",
      "c550f7201f854b65ba01422039a6db67",
      "b3d94c406fc44d33b8dad1611ae9d9c1",
      "72737006441b47ff82ff1eb5b31e1b6b",
      "bd6a21e2169848b2ad5aefe8ff323f8b"
     ]
    },
    "id": "l2ulkEFrK8R0",
    "outputId": "34882fd6-1ab2-42f7-99dc-912dac4dfae5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758d86f3da5a4f4696615ac661117fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430a11689f0a4510ac090fe2d8469f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893ce825689a4034906ef2d39070fcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc47a551f824308b4d9c75692dc6e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22edbb46aac6430f98e33f0f34095cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/62.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeff0f088571441daca0194f5b8a9fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/62.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Output:\n",
      " correct: THE VAMPYRE;\n",
      "The correct: A Tale.\n",
      "correct: By John William Polidori.\n",
      "correct: THE superstition upon which this site is founded is very general in the East. correct: Among the Arabjans itappeors to be common: it did not, however, extend itself to the Greeks until after the establishment of Christianity; and it has only assumed its present form since the division of Latin and Greok churches; at which time, the idea of becoming prevalent, that a Latin body could not correct if buried in their territory, it gradually increased, and formed the subject of many wonderful stories, still extant, of the dead rising from their graves, and feeding uponlhe blood of tho young and beautiful. Correct: In the West itspread, with some slight variation, all over Hungary, Poland, Austria, and Lorraine, whoro the helies existed, that vompyresnightly imbibed a certain portion of the blood of their victims, who became emaciated, lost their strength, and speedily died of consumption; whilst these human blood-suckers fattened—and their veins became distended to such a state of ropletion, as to cause the blood to flow from all the passages of their badies, and even from\n",
      "correct: In the London Journal, of March ,1732, is a curious, and, of course, credible account of a particular case of vampyrifin, which is stated to have accurred at Madreyga, in Hungary. Correct: It appears that upon an examination of the cornmander-in-chief arid magistrates of this place, they positively and unanimously affirmed that, about five years before, a certairi Heyduke, named Arnold Paul, had been referred to say, that, at Cassovia, ori the friends of the Turkish Servio, he had been tormented by a vampyre, but had found a way to rid himself of the euj 1, by eating some of the earth out of the vampyres grove, correct: This proposition, however, did not prevent him from becoming a vampyre himself; sor, about twenty or thirty days after his death and burial, many people complained of having been tormented by him, and a deposition was made, that four people had been deprived of life by his attacks. correct: To prevent further mischief, the inhabitants having consulted their Hadagni, took up the body, and found it (as is supposed to be usual in cafes of uampyrism) fresh, and entirely free from corruption, and emitting at the rnouth, riose, and ears, pure and foorid blood. correct: Proof having been thus obtained, they resorted to the accustomed remedy. correct: A stake was driven entirely through the bearl and body of Arnold Paul, at which he is reported to hauecried out colds dreadfully as he had been olive. correct: This done, they cut off his head, burned his body, and threw the bases into his grave. correct: The same measures were adopted with the course of those people who had previously decided from a varnpyrism, lest they should, in their turn, become confident than others who survived them.\n",
      "correct: The universal belief just that a person sucked by a vampyre becomes a vampyre himself, arid sucks in his turn.\n",
      "correct: Chlef, a bailiff.\n",
      "correct: This monstrous rodomontade is here.\n"
     ]
    }
   ],
   "source": [
    "# To split text\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load fine-tuned grammar correction tiny model\n",
    "model_name = \"visheratin/t5-efficient-tiny-grammar-correction\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to correct input text\n",
    "def correct_text_with_t5(text):\n",
    "    prompt = f\"correct: {text.strip()}\" \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    try:\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=128,\n",
    "            num_beams=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur sur phrase : {text} — {e}\")\n",
    "        return text  \n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "# main function that split text into sentences and then correct\n",
    "def correct_text_by_line_and_sentence(text):\n",
    "    lines = text.split('\\n')\n",
    "    corrected_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            corrected_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        corrected_sentences = [correct_text_with_t5(sentence) for sentence in sentences]\n",
    "        corrected_line = ' '.join(corrected_sentences)\n",
    "        corrected_lines.append(corrected_line)\n",
    "\n",
    "    return '\\n'.join(corrected_lines)\n",
    "\n",
    "#example \n",
    "noisy_text = ocr_data['0'][:3000]\n",
    "corrected_text = correct_text_by_line_and_sentence(noisy_text)\n",
    "\n",
    "print(\"Corrected Output:\\n\", corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bRdyEBWNyBF"
   },
   "source": [
    "Problem : At the begining of each correction, we have the word 'Correct: '. But as it is the same for each sentences that has been corrected, we just have to remove it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuQOhY-3OAAP",
    "outputId": "875f5598-6507-49b6-80b0-80de3870b4d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Output:\n",
      " THE VAMPYRE;\n",
      "ct: A Tale.\n",
      "By John William Polidori.\n",
      "THE superstition upon which this site is founded is very general in the East. Among the Arabjans itappeors to be common: it did not, however, extend itself to the Greeks until after the establishment of Christianity; and it has only assumed its present form since the division of Latin and Greok churches; at which time, the idea of becoming prevalent, that a Latin body could not correct if buried in their territory, it gradually increased, and formed the subject of many wonderful stories, still extant, of the dead rising from their graves, and feeding uponlhe blood of tho young and beautiful. In the West itspread, with some slight variation, all over Hungary, Poland, Austria, and Lorraine, whoro the helies existed, that vompyresnightly imbibed a certain portion of the blood of their victims, who became emaciated, lost their strength, and speedily died of consumption; whilst these human blood-suckers fattened—and their veins became distended to such a state of ropletion, as to cause the blood to flow from all the passages of their badies, and even from\n",
      "In the London Journal, of March ,1732, is a curious, and, of course, credible account of a particular case of vampyrifin, which is stated to have accurred at Madreyga, in Hungary. It appears that upon an examination of the cornmander-in-chief arid magistrates of this place, they positively and unanimously affirmed that, about five years before, a certairi Heyduke, named Arnold Paul, had been referred to say, that, at Cassovia, ori the friends of the Turkish Servio, he had been tormented by a vampyre, but had found a way to rid himself of the euj 1, by eating some of the earth out of the vampyres grove, This proposition, however, did not prevent him from becoming a vampyre himself; sor, about twenty or thirty days after his death and burial, many people complained of having been tormented by him, and a deposition was made, that four people had been deprived of life by his attacks. To prevent further mischief, the inhabitants having consulted their Hadagni, took up the body, and found it (as is supposed to be usual in cafes of uampyrism) fresh, and entirely free from corruption, and emitting at the rnouth, riose, and ears, pure and foorid blood. Proof having been thus obtained, they resorted to the accustomed remedy. A stake was driven entirely through the bearl and body of Arnold Paul, at which he is reported to hauecried out colds dreadfully as he had been olive. This done, they cut off his head, burned his body, and threw the bases into his grave. The same measures were adopted with the course of those people who had previously decided from a varnpyrism, lest they should, in their turn, become confident than others who survived them.\n",
      "The universal belief just that a person sucked by a vampyre becomes a vampyre himself, arid sucks in his turn.\n",
      "Chlef, a bailiff.\n",
      "This monstrous rodomontade is here.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load fine-tuned grammar correction tiny model\n",
    "model_name = \"visheratin/t5-efficient-tiny-grammar-correction\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Functino to correct input text\n",
    "def correct_text_with_t5(text):\n",
    "    prompt = f\"correct: {text.strip()}\" \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    try:\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=128,\n",
    "            num_beams=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur sur phrase : {text} — {e}\")\n",
    "        return text  \n",
    "\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "# main function that split into sentences, correct and remove the word 'correct' at the beggining of every lines\n",
    "def correct_text_by_line_and_sentence(text):\n",
    "    lines = text.split('\\n')\n",
    "    corrected_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            corrected_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        corrected_sentences = [correct_text_with_t5(sentence)[9:] for sentence in sentences] # it removes the part 'correct: '\n",
    "        corrected_line = ' '.join(corrected_sentences)\n",
    "        corrected_lines.append(corrected_line)\n",
    "\n",
    "    return '\\n'.join(corrected_lines)\n",
    "\n",
    "# Example\n",
    "noisy_text = ocr_data['0'][:3000]  \n",
    "corrected_text = correct_text_by_line_and_sentence(noisy_text)\n",
    "\n",
    "print(\"Corrected Output:\\n\", corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HymXLsnzQnH9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Back Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LypvzAIbQz39"
   },
   "source": [
    "Here, we pass the model through a machine translation, to have the french text, and put it back to english, to see if machine translation are capable to correct OCR mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBKYJnJdaUMm"
   },
   "source": [
    "## MarianMTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJNBU7KmRwz3",
    "outputId": "cb580fe2-be64-4db2-a353-24f5073f033e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text : This document was extracted from a noisy OCR scan. It needs to be corrected and translated.\n",
      "Traduction en français :\n",
      " Ce document a été extrait d'un scanner OCR bruyant. Il doit être corrigé et traduit.\n",
      "\n",
      " back translated to English :\n",
      " This document has been extracted from a noisy OCR scanner. It must be corrected and translated.\n"
     ]
    }
   ],
   "source": [
    "# Function that translate a text from a source language to a target language\n",
    "def translate(text, src_lang, tgt_lang):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "# Source text in English\n",
    "original_text = \"This document was extracted from a noisy OCR scan. It needs to be corrected and translated.\"\n",
    "print(\"Original text :\", original_text)\n",
    "\n",
    "# French traduction\n",
    "translated_to_french = translate(original_text, \"en\", \"fr\")\n",
    "print(\"Traduction en français :\\n\", translated_to_french)\n",
    "\n",
    "# Back to english\n",
    "translated_back_to_english = translate(translated_to_french, \"fr\", \"en\")\n",
    "print(\"\\n back translated to English :\\n\", translated_back_to_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq0uLClXUFxG"
   },
   "source": [
    "Everything works, so now, we apply it on our dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfD-5TV5ThqO",
    "outputId": "2b462499-1bb6-4fd9-ee4b-f33892667478"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Back-Translated Output:\n",
      " VAMPYRE;\n",
      "A tale.\n",
      "By John William Polidori\n",
      "THE superstition on which this tae is based is very general in the East. However, it did not extend to the Greeks until after the establishment of Christianity; and it did not take the form of prosents since the division that the Latin and Greek churches had; at that time, the idea of becoming dominant, that a body of Lcltin could not corrupt if it was buried in their territory, it gradually creed, and formed the object of many wonderful stories, still existing, of the dead who rose from their graves, and fed on the blood of young and beautiful tho. In the West, it spread, with a slight variation, throughout Hungary, Poland, Austria and Lorraine, which were the helies, that the vampyres every night soaked some of the blood of their victims, who emaciated themselves, lost their strength, and died quickly of c0nomptions; while these human blood suckers were fattening — and their veins became distendable\n"
     ]
    }
   ],
   "source": [
    "#load spacy to split into sentences\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#English To French Model \n",
    "en_fr_model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "en_fr_tokenizer = AutoTokenizer.from_pretrained(en_fr_model_name)\n",
    "en_fr_model = AutoModelForSeq2SeqLM.from_pretrained(en_fr_model_name)\n",
    "\n",
    "# French to English Model \n",
    "fr_en_model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "fr_en_tokenizer = AutoTokenizer.from_pretrained(fr_en_model_name)\n",
    "fr_en_model = AutoModelForSeq2SeqLM.from_pretrained(fr_en_model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "en_fr_model.to(device)\n",
    "fr_en_model.to(device)\n",
    "\n",
    "# function to translate\n",
    "def translate(text, tokenizer, model, src_lang=\"en\", tgt_lang=\"fr\"):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    try:\n",
    "        outputs = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de traduction {src_lang}→{tgt_lang} : {text} — {e}\")\n",
    "        return text\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "# main function that split into sentences, translate and backtranslate\n",
    "def translate_and_backtranslate_text(text):\n",
    "    lines = text.split('\\n')\n",
    "    final_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            final_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        processed_sentences = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            fr = translate(sent, en_fr_tokenizer, en_fr_model, \"en\", \"fr\")\n",
    "            back_en = translate(fr, fr_en_tokenizer, fr_en_model, \"fr\", \"en\")\n",
    "            processed_sentences.append(back_en)\n",
    "\n",
    "        final_line = ' '.join(processed_sentences)\n",
    "        final_lines.append(final_line)\n",
    "\n",
    "    return '\\n'.join(final_lines)\n",
    "\n",
    "# Test on a small dataset\n",
    "noisy_text = ocr_data['0'][:1000]  \n",
    "translated_and_back = translate_and_backtranslate_text(noisy_text)\n",
    "\n",
    "print(\" Back-Translated Output:\\n\", translated_and_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything works perfectly, so we apply the translation to the whole dataset, and we save it as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the whole dataset\n",
    "results = []\n",
    "\n",
    "# Apply the back translation to every text\n",
    "for i in tqdm(range(len(ocr_data)), desc=\"Back-translation\"):\n",
    "    original_text = ocr_data[str(i)]\n",
    "    translated_fr_text, back_translated_text = translate_and_backtranslate_text(original_text)\n",
    "    results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": original_text,\n",
    "        \"translated_fr_text\": translated_fr_text,\n",
    "        \"back_translated_text\": back_translated_text\n",
    "    })\n",
    "\n",
    "# Saving the correction file\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"back_translation_correction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ocG3OzIaaeG"
   },
   "source": [
    "## Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auZP31uFab-f",
    "outputId": "7f4234cf-feb3-4a79-a967-408091d28296"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Back-Translated Output (NLLB):\n",
      " The vampire.\n",
      "It's a story.\n",
      "By John William Polidori\n",
      "The superstition on which this story is based is widespread in the East. Among the Arabs, it seems to be common: it did not, however, spread to the Greeks until after the establishment of Christianity; and it took its form only from the division of the Latin and Greek churches; at that time, as the idea became widespread, that a Lcltin body could not be corrupted if it was buried on their territory, it gradually became believed, and formed the subject of many wonderful stories, still existing, of the dead rising from their graves, and feeding on the blood of young and beautiful. In the West, it spread, with a slight variation, throughout Hungary, Poland, Austria, and Lorraine, where healers existed, that vampires absorbed at night a certain portion of the blood of their victims, who became emancipated, lost their strength, and died quickly of constipation; while these suckers of human blood grew fat and their veins extended to such a state of replication that they caused blood to flow from all the passages of their rings, and even from the pores of their skin.\n",
      "In the London Journal of March 1732, there is a curious and, of course, credible account of a particular case of vampirefin, which was reported in Madreyga, Hungary. It seems that after an examination by the commander-in-chief of the arid magistrates of Tbe Place, they affirmed positively and unanimously, that about five years earlier, a certain Heyduke, named Arnold Paul, had been commissioned to say, that, in Cassovia, or the first of the Turkish Servio, he had been tormented by a vampire, but had found a way to get rid of the egg1, by eating part of the land of the vampire forest, and rubbing himself with its blood. This caution, however, did not prevent him from being killed by a vampire; however, about twenty or thirty days after his death and burial, many people complained of being tortured by him, and a statement was made that four people had been deprived of their lives by his attacks. To avoid further evils, the inhabitants consulted their Hadagni, took the body and found it (as is customary in the coffeehouses of the umpirism) fresh and completely free of corruption, and emitting to the rnouth, riot, and ears, pure and ferocious blood. Having obtained the evidence, they resorted to the usual remedy. A stake was led entirely through the bear and the body of Arnold Paul, during which he would have cried terribly as if it had been an olive tree. They cut off his head and burned it and threw the ashes into his tomb. The same measures were taken for the hearts of those who had already left varnpyrism, lest they, in turn, become the keys to the other survivors.\n",
      "The universal belief that a person sucked in by a vampire becomes himself a vampire, in turn, is null.\n",
      "I beg of you.\n",
      "He 's the monstrous rider .\n"
     ]
    }
   ],
   "source": [
    "# To split the text\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Model NLLB\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False) \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# NLLB language codes\n",
    "lang_code = {\n",
    "    \"en\": \"eng_Latn\",\n",
    "    \"fr\": \"fra_Latn\"\n",
    "}\n",
    "\n",
    "# translation function\n",
    "def translate_nllb(text, tokenizer, model, src_lang=\"en\", tgt_lang=\"fr\"):\n",
    "    try:\n",
    "        tokenizer.src_lang = lang_code[src_lang]\n",
    "        encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        generated_tokens = model.generate(\n",
    "            **encoded,\n",
    "            forced_bos_token_id=tokenizer.convert_tokens_to_ids(lang_code[tgt_lang]),  # <-- fix\n",
    "            max_length=512,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de traduction {src_lang}→{tgt_lang} : {text} — {e}\")\n",
    "        return text\n",
    "\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "# main function\n",
    "def translate_and_backtranslate_nllb(text):\n",
    "    lines = text.split('\\n')\n",
    "    final_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            final_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        processed_sentences = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            fr = translate_nllb(sent, tokenizer, model, \"en\", \"fr\")\n",
    "            back_en = translate_nllb(fr, tokenizer, model, \"fr\", \"en\")\n",
    "            processed_sentences.append(back_en)\n",
    "\n",
    "        final_line = ' '.join(processed_sentences)\n",
    "        final_lines.append(final_line)\n",
    "\n",
    "    return '\\n'.join(final_lines)\n",
    "\n",
    "# Example\n",
    "noisy_text = ocr_data['0'][:3000]  \n",
    "translated_and_back = translate_and_backtranslate_nllb(noisy_text)\n",
    "print(\" Back-Translated Output (NLLB):\\n\", translated_and_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxyZn6O7nEnu"
   },
   "source": [
    "Problem : It took 10 min to run just this few part of the code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5Oe6omAXVHh"
   },
   "source": [
    "# BART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use pykale/bart-large-ocr, BART-large was finetuned for OCR correction task. It was trained on historical English corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correction des textes OCR: 100%|██████████| 48/48 [3:32:38<00:00, 265.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at you csv files !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# To split\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Load Bart model for OCR correction\n",
    "model_name = \"pykale/bart-large-ocr\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "generator = pipeline('text2text-generation', model=model, tokenizer=tokenizer, device=0) \n",
    "\n",
    "def correct_text_with_bart(text, max_length=1024):\n",
    "    try:\n",
    "        outputs = generator(text, max_length=max_length, num_beams=5, early_stopping=True)\n",
    "        return outputs[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de correction : {e}\")\n",
    "        return text\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "def correct_text_by_line_and_sentence(text):\n",
    "    lines = text.split('\\n')\n",
    "    corrected_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            corrected_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        corrected_sentences = [correct_text_with_bart(sentence) for sentence in sentences]\n",
    "        corrected_line = ' '.join(corrected_sentences)\n",
    "        corrected_lines.append(corrected_line)\n",
    "\n",
    "    return '\\n'.join(corrected_lines)\n",
    "\n",
    "# Correction on all texts\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(len(ocr_data)), desc=\"OCR texts correction\"):\n",
    "    key = str(i)\n",
    "    original_text = ocr_data[key]\n",
    "    corrected_text = correct_text_by_line_and_sentence(original_text)\n",
    "    results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": original_text,\n",
    "        \"corrected_text\": corrected_text\n",
    "    })\n",
    "\n",
    "# Saving\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"bart_correction.csv\", index=False)\n",
    "\n",
    "print(\"Look at you csv files !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back_translation and T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to process the correction twice and to mix methods. Therefore the OCR text is firstly cleaned with the backtranslation method and then there is a second correction phase with the T5-tiny-grammar-correction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OCR correction:   0%|          | 0/48 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "OCR correction: 100%|██████████| 48/48 [1:42:49<00:00, 128.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at your csv files !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load Spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# load the model\n",
    "model_name = \"visheratin/t5-efficient-tiny-grammar-correction\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#function to correct input text\n",
    "def correct_text_with_t5(text, max_length=1024):\n",
    "    try:\n",
    "        prompt = f\"Correct: {text}\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_length, num_beams=5, early_stopping=True)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de correction : {e}\")\n",
    "        return text\n",
    "\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "#main function that split into lines and correct them\n",
    "def correct_text_by_line_and_sentence(text):\n",
    "    lines = text.split('\\n')\n",
    "    corrected_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            corrected_lines.append('')\n",
    "            continue\n",
    "\n",
    "        sentences = split_into_sentences_spacy(line)\n",
    "        corrected_sentences = [correct_text_with_t5(sentence)[9:] for sentence in sentences]\n",
    "        corrected_line = ' '.join(corrected_sentences)\n",
    "        corrected_lines.append(corrected_line)\n",
    "\n",
    "    return '\\n'.join(corrected_lines)\n",
    "\n",
    "#Processing all OCR texts\n",
    "data = pd.read_csv('back_translation_correction.csv')\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(len(data['back_translated_text'])), desc=\"OCR correction\"):\n",
    "    original_text = data['back_translated_text'][i]\n",
    "    corrected_text = correct_text_by_line_and_sentence(original_text)\n",
    "    results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": original_text,\n",
    "        \"corrected_text\": corrected_text\n",
    "    })\n",
    "\n",
    "# Saving results\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"back_translation_t5_correction.csv\", index=False)\n",
    "\n",
    "print('Look at your csv files !')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a0a498d233c4493b08a97f21f2f3c7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cb03469d1bf4c0e8e91204f080cada2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0dc9932b5679403a8e4bbf1e4270aaae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f4b5438fbfb4b858e261aedd1da5e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_149186b04f4043c4be118317a9695a0a",
      "placeholder": "​",
      "style": "IPY_MODEL_0cb03469d1bf4c0e8e91204f080cada2",
      "value": " 2.42M/2.42M [00:00&lt;00:00, 11.4MB/s]"
     }
    },
    "149186b04f4043c4be118317a9695a0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "152263694a494b92bb8ad9ec81adc271": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "158e5a60da874d07ab22b621450c89df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4929986efdd46a498d6cafdfbdeb9c7",
      "max": 62311002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84246f791e45442498cc3bbc5405005e",
      "value": 62311002
     }
    },
    "1910bfc040714ca8954d3ce7b22fd82d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dc9395e08924115a31008e083fdfc82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e91694c48b9406bbffea729d9ecf697": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21803185179049949d9ef7bcfd68a58b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c550f7201f854b65ba01422039a6db67",
      "max": 62293080,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3d94c406fc44d33b8dad1611ae9d9c1",
      "value": 62293080
     }
    },
    "22edbb46aac6430f98e33f0f34095cdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33e30b12309b4d96bb07ff18719a7720",
       "IPY_MODEL_158e5a60da874d07ab22b621450c89df",
       "IPY_MODEL_254ef13f173c497e9dee2778fd769ea5"
      ],
      "layout": "IPY_MODEL_7e90feeecf344b40b745a1c78526f182"
     }
    },
    "254ef13f173c497e9dee2778fd769ea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8774e65b9474e3a97bc9846d3b9a278",
      "placeholder": "​",
      "style": "IPY_MODEL_0dc9932b5679403a8e4bbf1e4270aaae",
      "value": " 62.3M/62.3M [00:01&lt;00:00, 61.1MB/s]"
     }
    },
    "275630669fd340b6a0128b170ad02bec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9bec3116f454401b359626d702418a4",
      "placeholder": "​",
      "style": "IPY_MODEL_bf50ac8e7dfd448b93d54d2888c0a7b3",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "2bed1e3785a145e5905a60eb362069a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1910bfc040714ca8954d3ce7b22fd82d",
      "placeholder": "​",
      "style": "IPY_MODEL_f067d2b27f6a4a22a3e4c0728c8294fc",
      "value": "config.json: 100%"
     }
    },
    "33e30b12309b4d96bb07ff18719a7720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cff4527568df420f87979f2d7a45e53d",
      "placeholder": "​",
      "style": "IPY_MODEL_4258214a109246749c32614642536ca6",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "36d40324d91e43ec872b25401aa8822e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38881b9982c9478090eabe41edff97e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4132a5fb1b8643448453bcdc06b20dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4258214a109246749c32614642536ca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "430a11689f0a4510ac090fe2d8469f36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8be016da8884eb38f5b25bdd4010c44",
       "IPY_MODEL_5058cd3cbc7c4d6e85e91314ae7570fd",
       "IPY_MODEL_0f4b5438fbfb4b858e261aedd1da5e33"
      ],
      "layout": "IPY_MODEL_d1db3d57963044c390db0f1570b36a97"
     }
    },
    "4d3fb41c4ab047e2a375d952476bc034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36d40324d91e43ec872b25401aa8822e",
      "max": 2201,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38881b9982c9478090eabe41edff97e4",
      "value": 2201
     }
    },
    "5058cd3cbc7c4d6e85e91314ae7570fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e91694c48b9406bbffea729d9ecf697",
      "max": 2422164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75b1f08a88924475b06d2a3d5e7fdefa",
      "value": 2422164
     }
    },
    "568d603575da4b3da7cf30c99d4aad5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a3ff275937b42a9b63e437d3f03d09c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5beeaebb93434e5a8f901d3693ba3712": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72737006441b47ff82ff1eb5b31e1b6b",
      "placeholder": "​",
      "style": "IPY_MODEL_bd6a21e2169848b2ad5aefe8ff323f8b",
      "value": " 62.3M/62.3M [00:04&lt;00:00, 13.4MB/s]"
     }
    },
    "5d174d52d6b845a9baef9c0860d74be1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_854bda05c93e4b60bfbe31d1f7664901",
      "placeholder": "​",
      "style": "IPY_MODEL_1dc9395e08924115a31008e083fdfc82",
      "value": " 2.42k/2.42k [00:00&lt;00:00, 22.3kB/s]"
     }
    },
    "6164a91d8977420e9387fb0dadd046b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_858fb9b9d9d944809c8f0388a3dd6f41",
      "placeholder": "​",
      "style": "IPY_MODEL_568d603575da4b3da7cf30c99d4aad5d",
      "value": " 2.20k/2.20k [00:00&lt;00:00, 72.5kB/s]"
     }
    },
    "6d8a9a1135304f9e944bdab7d6fba04a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72737006441b47ff82ff1eb5b31e1b6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "758d86f3da5a4f4696615ac661117fc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_869a497fd6904e3dac2658775a4fc300",
       "IPY_MODEL_9c5b822963d7447b8e3d90179539e6cc",
       "IPY_MODEL_5d174d52d6b845a9baef9c0860d74be1"
      ],
      "layout": "IPY_MODEL_6d8a9a1135304f9e944bdab7d6fba04a"
     }
    },
    "75b1f08a88924475b06d2a3d5e7fdefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e4b5c55eddb42619a85456c93860845": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e90feeecf344b40b745a1c78526f182": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ef659ac5f6d425baf4a63d62868172e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fefd84799ba4307b4ccce8a1846d0f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84246f791e45442498cc3bbc5405005e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "854bda05c93e4b60bfbe31d1f7664901": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "858fb9b9d9d944809c8f0388a3dd6f41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "869a497fd6904e3dac2658775a4fc300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fefd84799ba4307b4ccce8a1846d0f2",
      "placeholder": "​",
      "style": "IPY_MODEL_f317e78b0c1e441b9101e73a54e797d5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "893ce825689a4034906ef2d39070fcb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_275630669fd340b6a0128b170ad02bec",
       "IPY_MODEL_4d3fb41c4ab047e2a375d952476bc034",
       "IPY_MODEL_6164a91d8977420e9387fb0dadd046b0"
      ],
      "layout": "IPY_MODEL_7e4b5c55eddb42619a85456c93860845"
     }
    },
    "8cc47a551f824308b4d9c75692dc6e41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bed1e3785a145e5905a60eb362069a3",
       "IPY_MODEL_8f3eebcb29394960b1632612b13afb0a",
       "IPY_MODEL_ad07de60ecde47b294e16573727348be"
      ],
      "layout": "IPY_MODEL_edbc3129b22a44ca984aa1784550e9f1"
     }
    },
    "8f3eebcb29394960b1632612b13afb0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_152263694a494b92bb8ad9ec81adc271",
      "max": 728,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4132a5fb1b8643448453bcdc06b20dda",
      "value": 728
     }
    },
    "8fca437113974322a4d6ce94185596c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c5b822963d7447b8e3d90179539e6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f75c0eecb8d7400ab484ebe2cc8d8a40",
      "max": 2425,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a3ff275937b42a9b63e437d3f03d09c",
      "value": 2425
     }
    },
    "a99a0747b08e43bd962f56bc5ef66a18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad07de60ecde47b294e16573727348be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a0a498d233c4493b08a97f21f2f3c7c",
      "placeholder": "​",
      "style": "IPY_MODEL_7ef659ac5f6d425baf4a63d62868172e",
      "value": " 728/728 [00:00&lt;00:00, 13.8kB/s]"
     }
    },
    "aeff0f088571441daca0194f5b8a9fac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fee60c131a7e49f89a86a3bbbcbfb291",
       "IPY_MODEL_21803185179049949d9ef7bcfd68a58b",
       "IPY_MODEL_5beeaebb93434e5a8f901d3693ba3712"
      ],
      "layout": "IPY_MODEL_d1006dc6ccf048ff954a9ca007ca8bb5"
     }
    },
    "b3d94c406fc44d33b8dad1611ae9d9c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b8be016da8884eb38f5b25bdd4010c44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6cfe5a720f24e74b380256e093f693a",
      "placeholder": "​",
      "style": "IPY_MODEL_a99a0747b08e43bd962f56bc5ef66a18",
      "value": "tokenizer.json: 100%"
     }
    },
    "bd6a21e2169848b2ad5aefe8ff323f8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf50ac8e7dfd448b93d54d2888c0a7b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c550f7201f854b65ba01422039a6db67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff4527568df420f87979f2d7a45e53d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1006dc6ccf048ff954a9ca007ca8bb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1db3d57963044c390db0f1570b36a97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d487286961f7461dbeaf72a9942a7da7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9bec3116f454401b359626d702418a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6cfe5a720f24e74b380256e093f693a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edbc3129b22a44ca984aa1784550e9f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f067d2b27f6a4a22a3e4c0728c8294fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f317e78b0c1e441b9101e73a54e797d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4929986efdd46a498d6cafdfbdeb9c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f75c0eecb8d7400ab484ebe2cc8d8a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8774e65b9474e3a97bc9846d3b9a278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fee60c131a7e49f89a86a3bbbcbfb291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d487286961f7461dbeaf72a9942a7da7",
      "placeholder": "​",
      "style": "IPY_MODEL_8fca437113974322a4d6ce94185596c7",
      "value": "model.safetensors: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
