{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d79d5c-24b0-4bf7-9d0c-63077241f3b3",
   "metadata": {},
   "source": [
    "# Import gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5175b99-4aec-404c-b22e-6fdcc682cc67",
   "metadata": {},
   "source": [
    "Link to the documentation : https://ai.google.dev/gemini-api/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d2b1ed-8a50-4ddd-9ec5-8243f08c0814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'google-api-python-client' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-api-python-client'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0cea90e-8422-4cdc-aba2-13642e1f7d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns and reasons like humans, but using computers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "# Use the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")  # or \"gemini-1.5-pro\"\n",
    "\n",
    "response = model.generate_content(\"Explain how AI works in a few words\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c6224-2df5-4cd5-85cc-1848b31df33f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ecc2d-8be0-4e5f-87ad-d24e939b2f2b",
   "metadata": {},
   "source": [
    "Here are the criteria for the attribution of the score to corrected OCRed texts :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876c60e-c52d-4c1f-85a1-760c60d860e9",
   "metadata": {},
   "source": [
    "| **Score**         | **Criteria**                                                                                                                                                                    |\n",
    "| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1 - Very Poor** | The text remains largely unreadable. Numerous errors persist (spelling, grammar, punctuation). The overall meaning is lost or extremely unclear. Little to no improvement made. |\n",
    "| **2 - Poor**      | Slightly more readable than the original, but many errors remain. Several sentences are incorrect or ambiguous. Words are still distorted or missing.                           |\n",
    "| **3 - Fair**      | Most obvious errors have been corrected. The text is generally understandable, but noticeable mistakes and awkward phrasing remain. The flow may be choppy.                     |\n",
    "| **4 - Good**      | The text is readable and coherent. Only minor errors remain. There’s overall consistency, though a few syntax or word choice issues may still be present.                       |\n",
    "| **5 - Excellent** | The text is fully corrected: no detectable mistakes, perfect grammar, punctuation, and syntax. The result is fluent, natural, and faithful to the original content.             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1642b84-ff4c-4a6c-9726-3113eb8add59",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acb440-8475-4849-904f-9edf14a8e55c",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f2b60f-d5ab-430a-be25-a70f5fa6f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Chemin vers le dossier où les fichiers ont été extraits\n",
    "extract_dir = os.path.expanduser(\"~/work/MNLP-project-2/data/eng\")\n",
    "\n",
    "# Chemins complets vers les fichiers JSON\n",
    "clean_path = os.path.join(extract_dir, \"the_vampyre_clean.json\")\n",
    "ocr_path = os.path.join(extract_dir, \"the_vampyre_ocr.json\")\n",
    "\n",
    "# Chargement des données JSON\n",
    "with open(clean_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clean_data = json.load(f)\n",
    "\n",
    "with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ocr_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b4116d-8002-4193-b5da-7abd46fe7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_values_dict(d):\n",
    "    \"\"\"\n",
    "    Concat values of a dict, seperating each element with '\\n'\n",
    "\n",
    "    Args:\n",
    "        d (dict): Dictionnary\n",
    "\n",
    "    Returns:\n",
    "        str: concatenated text\n",
    "    \"\"\"\n",
    "    return '\\n'.join(d.get(str(i), \"\") for i in range(48))\n",
    "\n",
    "clean_data_text = concat_values_dict(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ac732b-e559-4afd-b497-cb10190a1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62205"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d5862-942d-4081-b214-a2329f5c1d0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68a06c1f-b66e-4c0a-aefa-5a26d86fdfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...</td>\n",
       "      <td>THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy Johri William Polido...</td>\n",
       "      <td>THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...</td>\n",
       "      <td>THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John Wjlliam Polidor...</td>\n",
       "      <td>THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy Jahn William PoIjdor...</td>\n",
       "      <td>THE VAMPYRE;\\nct: A Tale.\\nBy John William Poj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           original_text  \\\n",
       "index                                                      \n",
       "0      THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...   \n",
       "1      THE VAMPYRE;\\nA Tale.\\nBy Johri William Polido...   \n",
       "2      THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...   \n",
       "3      THE VAMPYRE;\\nA Tale.\\nBy John Wjlliam Polidor...   \n",
       "4      THE VAMPYRE;\\nA Tale.\\nBy Jahn William PoIjdor...   \n",
       "\n",
       "                                          corrected_text  \n",
       "index                                                     \n",
       "0      THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...  \n",
       "1      THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...  \n",
       "2      THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...  \n",
       "3      THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...  \n",
       "4      THE VAMPYRE;\\nct: A Tale.\\nBy John William Poj...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "T5_correction = pd.read_csv('T5_correction.csv', index_col=0)\n",
    "T5_correction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ea517-aefa-41ba-9f3a-0711867763d0",
   "metadata": {},
   "source": [
    "We can not put all the translations in the LLM as a judge, so we build some batches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7657274d-e368-409a-a850-188c5e973b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille des batches\n",
    "batch_size = 1\n",
    "\n",
    "# Diviser le DataFrame en batches\n",
    "batches = [T5_correction[i:i + batch_size] for i in range(0, len(T5_correction), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "842b97f1-7458-4040-9b43-30bf32a0e6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...</td>\n",
       "      <td>THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           original_text  \\\n",
       "index                                                      \n",
       "0      THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...   \n",
       "\n",
       "                                          corrected_text  \n",
       "index                                                     \n",
       "0      THE VAMPYRE;\\nct: A Tale.\\nBy John William Pol...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71cd72ce-3528-458f-a79f-088053bac1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60430"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches[0]['corrected_text'].to_list()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e63b98-8d06-4780-b124-cd0f1e873b33",
   "metadata": {},
   "source": [
    "# Evaluation thanks to LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae8ec6-6124-47dd-abda-90195b708066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 0 / 48...\n",
      "Waiting 60 seconds before next text...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from google.generativeai import GenerativeModel\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=\"AIzaSyDRBH-RcZzo9i4jW08r2rndm7gPJ2BRYg0\")\n",
    "\n",
    "# Initialise Gemini model\n",
    "model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "\n",
    "# Divise le texte en morceaux pour ne pas dépasser les limites d'entrée\n",
    "def chunk_text(text, max_chunk_size=5000):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + max_chunk_size\n",
    "        if end < len(text):\n",
    "            last_space = text.rfind(\" \", start, end)\n",
    "            if last_space != -1 and last_space > start:\n",
    "                end = last_space\n",
    "        chunks.append(text[start:end].strip())\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "# Prompt d'évaluation uniquement avec un score\n",
    "def build_prompt_score_only(chunk):\n",
    "    return f\"\"\"You are a text quality evaluator. Evaluate the following corrected OCR text based on the detailed criteria below:\n",
    "\n",
    "1 - Very Poor: The text remains largely unreadable. Numerous errors persist (spelling, grammar, punctuation). The overall meaning is lost or extremely unclear. Little to no improvement made.\n",
    "2 - Poor: Slightly more readable than the original, but many errors remain. Several sentences are incorrect or ambiguous. Words are still distorted or missing.\n",
    "3 - Fair: Most obvious errors have been corrected. The text is generally understandable, but noticeable mistakes and awkward phrasing remain. The flow may be choppy.\n",
    "4 - Good: The text is readable and coherent. Only minor errors remain. There’s overall consistency, though a few syntax or word choice issues may still be present.\n",
    "5 - Excellent: The text is fully corrected: no detectable mistakes, perfect grammar, punctuation, and syntax. The result is fluent, natural, and faithful to the original content.\n",
    "\n",
    "Give only the numeric score (1 to 5). No explanation.\n",
    "\n",
    "Corrected Text:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\"\"\"\n",
    "\n",
    "# Évalue chaque chunk de texte\n",
    "def evaluate_text(text):\n",
    "    chunks = chunk_text(text)\n",
    "    scores_for_text = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        prompt = build_prompt_score_only(chunk)\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            raw_text = response.candidates[0].content.parts[0].text.strip()\n",
    "            score = int(raw_text) if raw_text in {\"1\", \"2\", \"3\", \"4\", \"5\"} else -1\n",
    "        except Exception as e:\n",
    "            print(f\"Error on chunk {i}: {e}\")\n",
    "            score = -1\n",
    "\n",
    "        scores_for_text.append(score)\n",
    "    return scores_for_text\n",
    "\n",
    "# Fonction principale\n",
    "def main():\n",
    "    all_scores = {}\n",
    "\n",
    "    for key in ocr_data:\n",
    "        print(f\"Processing text {key} / {len(ocr_data)}...\")\n",
    "        text = ocr_data[key]\n",
    "        scores = evaluate_text(text)\n",
    "        all_scores[key] = scores\n",
    "\n",
    "        # Pause anti-limite API\n",
    "        if key != list(ocr_data.keys())[-1]:\n",
    "            print(\"Waiting 60 seconds before next text...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    # Sauvegarde dans un CSV\n",
    "    rows = []\n",
    "    for text_index, scores_list in all_scores.items():\n",
    "        for chunk_index, score in enumerate(scores_list):\n",
    "            rows.append({\n",
    "                \"text_index\": text_index,\n",
    "                \"chunk_index\": chunk_index,\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "    df_scores = pd.DataFrame(rows)\n",
    "    df_scores.to_csv(\"ocr_gemini_scores.csv\", index=False)\n",
    "    print(\"Finished! CSV saved as 'ocr_gemini_scores.csv'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
