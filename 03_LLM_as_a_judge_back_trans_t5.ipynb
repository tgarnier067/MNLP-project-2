{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d79d5c-24b0-4bf7-9d0c-63077241f3b3",
   "metadata": {},
   "source": [
    "# Import gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5175b99-4aec-404c-b22e-6fdcc682cc67",
   "metadata": {},
   "source": [
    "Link to the documentation : https://ai.google.dev/gemini-api/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d2b1ed-8a50-4ddd-9ec5-8243f08c0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cea90e-8422-4cdc-aba2-13642e1f7d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI uses data to learn and make decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Test on the Gemini API\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")  # or \"gemini-1.5-pro\"\n",
    "\n",
    "response = model.generate_content(\"Explain how AI works in a few words\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c6224-2df5-4cd5-85cc-1848b31df33f",
   "metadata": {},
   "source": [
    "# Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ecc2d-8be0-4e5f-87ad-d24e939b2f2b",
   "metadata": {},
   "source": [
    "Here are the criteria for the attribution of the score to corrected OCRed texts :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876c60e-c52d-4c1f-85a1-760c60d860e9",
   "metadata": {},
   "source": [
    "| **Score**         | **Criteria**                                                                                                                                                                    |\n",
    "| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1 - Very Poor** | The text remains largely unreadable. Numerous errors persist (spelling, grammar, punctuation). The overall meaning is lost or extremely unclear. Little to no improvement made. |\n",
    "| **2 - Poor**      | Slightly more readable than the original, but many errors remain. Several sentences are incorrect or ambiguous. Words are still distorted or missing.                           |\n",
    "| **3 - Fair**      | Most obvious errors have been corrected. The text is generally understandable, but noticeable mistakes and awkward phrasing remain. The flow may be choppy.                     |\n",
    "| **4 - Good**      | The text is readable and coherent. Only minor errors remain. There’s overall consistency, though a few syntax or word choice issues may still be present.                       |\n",
    "| **5 - Excellent** | The text is fully corrected: no detectable mistakes, perfect grammar, punctuation, and syntax. The result is fluent, natural, and faithful to the original content.             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1642b84-ff4c-4a6c-9726-3113eb8add59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acb440-8475-4849-904f-9edf14a8e55c",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f2b60f-d5ab-430a-be25-a70f5fa6f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Chemin vers le dossier où les fichiers ont été extraits\n",
    "extract_dir = os.path.expanduser(\"~/work/MNLP-project-2/data/eng\")\n",
    "\n",
    "# Chemins complets vers les fichiers JSON\n",
    "clean_path = os.path.join(extract_dir, \"the_vampyre_clean.json\")\n",
    "\n",
    "# Chargement des données JSON\n",
    "with open(clean_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clean_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b4116d-8002-4193-b5da-7abd46fe7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_values_dict(d):\n",
    "    \"\"\"\n",
    "    Concat values of a dict, seperating each element with '\\n'\n",
    "\n",
    "    Args:\n",
    "        d (dict): Dictionnary\n",
    "\n",
    "    Returns:\n",
    "        str: concatenated text\n",
    "    \"\"\"\n",
    "    return '\\n'.join(d.get(str(i), \"\") for i in range(48))\n",
    "\n",
    "clean_data_text = concat_values_dict(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ac732b-e559-4afd-b497-cb10190a1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e63b98-8d06-4780-b124-cd0f1e873b33",
   "metadata": {},
   "source": [
    "# Evaluation thanks to LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ae8ec6-6124-47dd-abda-90195b708066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 2 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 3 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 4 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 5 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 6 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 7 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 8 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 9 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 10 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 11 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 12 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 13 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 14 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 15 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 16 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 17 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 18 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 19 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 20 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 21 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 22 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 23 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 24 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 25 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 26 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 27 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 28 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 29 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 30 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 31 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 32 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 33 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 34 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 35 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 36 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 37 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 38 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 39 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 40 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 41 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 42 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 43 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 44 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 45 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 46 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 47 / 48...\n",
      "Waiting 60 seconds before next text...\n",
      "Processing text 48 / 48...\n",
      "Over : Look at your new CSV files :) \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from google.generativeai import GenerativeModel\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API key and model\n",
    "genai.configure(api_key=\"AIzaSyCI-RkwBmOuu4Iv5oTciRY2mrl8IIBTTBc\")\n",
    "model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "\n",
    "# Function that divides text into chunks (we can not give the whole text as input => it's too big)\n",
    "def chunk_text(text, max_chunk_size=5000):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + max_chunk_size\n",
    "        if end < len(text):\n",
    "            last_space = text.rfind(\" \", start, end)\n",
    "            if last_space != -1 and last_space > start:\n",
    "                end = last_space\n",
    "        chunks.append(text[start:end].strip())\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "# Build the prompt\n",
    "def build_prompt_score_only(chunk):\n",
    "    return f\"\"\"You are a text quality evaluator. Evaluate the following corrected OCR text based on the detailed criteria below:\n",
    "\n",
    "1 - Very Poor: The text remains largely unreadable. Numerous errors persist (spelling, grammar, punctuation). The overall meaning is lost or extremely unclear. Little to no improvement made.\n",
    "2 - Poor: Slightly more readable than the original, but many errors remain. Several sentences are incorrect or ambiguous. Words are still distorted or missing.\n",
    "3 - Fair: Most obvious errors have been corrected. The text is generally understandable, but noticeable mistakes and awkward phrasing remain. The flow may be choppy.\n",
    "4 - Good: The text is readable and coherent. Only minor errors remain. There’s overall consistency, though a few syntax or word choice issues may still be present.\n",
    "5 - Excellent: The text is fully corrected: no detectable mistakes, perfect grammar, punctuation, and syntax. The result is fluent, natural, and faithful to the original content.\n",
    "\n",
    "Give only the numeric score (1 to 5). No explanation.\n",
    "\n",
    "Corrected Text:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\"\"\"\n",
    "\n",
    "# Function that return the evaluation score for every chunks in a text\n",
    "def evaluate_text(text):\n",
    "    chunks = chunk_text(text, max_chunk_size=5000)\n",
    "    scores_for_text = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        prompt = build_prompt_score_only(chunk)\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            raw_text = response.candidates[0].content.parts[0].text.strip()\n",
    "            if raw_text in {\"1\", \"2\", \"3\", \"4\", \"5\"}:\n",
    "                score = int(raw_text)\n",
    "            else:\n",
    "                score = -1\n",
    "        except Exception as e:\n",
    "            print(f\"Error on chunk {i}: {e}\")\n",
    "            score = -1\n",
    "\n",
    "        scores_for_text.append(score)\n",
    "    return scores_for_text\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(\"back_translation_t5_correction.csv\")\n",
    "    all_scores = {}\n",
    "\n",
    "    for text_index in range(len(df)):\n",
    "        print(f\"Processing text {text_index + 1} / {len(df)}...\")\n",
    "        text = df.loc[text_index, \"corrected_text\"]\n",
    "\n",
    "        scores = evaluate_text(text)\n",
    "        all_scores[text_index] = scores\n",
    "\n",
    "        # 1 minute break because of the API\n",
    "        if text_index < len(df) - 1:\n",
    "            print(\"Waiting 60 seconds before next text...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    rows = []\n",
    "    for text_index, scores_list in all_scores.items():\n",
    "        for chunk_index, score in enumerate(scores_list):\n",
    "            rows.append({\n",
    "                \"text_index\": text_index,\n",
    "                \"chunk_index\": chunk_index,\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "    df_scores = pd.DataFrame(rows)\n",
    "    df_scores.to_csv(\"back_translation_t5_gemini_scores_all_texts.csv\", index=False)\n",
    "    print(\"Over : Look at your new CSV files :) \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
