{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d79d5c-24b0-4bf7-9d0c-63077241f3b3",
   "metadata": {},
   "source": [
    "# Import gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5175b99-4aec-404c-b22e-6fdcc682cc67",
   "metadata": {},
   "source": [
    "Link to the documentation : https://ai.google.dev/gemini-api/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d2b1ed-8a50-4ddd-9ec5-8243f08c0814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'google-api-python-client' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-api-python-client'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cea90e-8422-4cdc-aba2-13642e1f7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Test\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")  # or \"gemini-1.5-pro\"\n",
    "\n",
    "response = model.generate_content(\"Explain how AI works in a few words\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c6224-2df5-4cd5-85cc-1848b31df33f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ecc2d-8be0-4e5f-87ad-d24e939b2f2b",
   "metadata": {},
   "source": [
    "Here are the criteria for the attribution of the score to corrected OCRed texts :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876c60e-c52d-4c1f-85a1-760c60d860e9",
   "metadata": {},
   "source": [
    "| **Score**         | **Criteria**                                                                                                                                                                    |\n",
    "| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1 - Very Poor** | The text remains largely unreadable. Numerous errors persist (spelling, grammar, punctuation). The overall meaning is lost or extremely unclear. Little to no improvement made. |\n",
    "| **2 - Poor**      | Slightly more readable than the original, but many errors remain. Several sentences are incorrect or ambiguous. Words are still distorted or missing.                           |\n",
    "| **3 - Fair**      | Most obvious errors have been corrected. The text is generally understandable, but noticeable mistakes and awkward phrasing remain. The flow may be choppy.                     |\n",
    "| **4 - Good**      | The text is readable and coherent. Only minor errors remain. There’s overall consistency, though a few syntax or word choice issues may still be present.                       |\n",
    "| **5 - Excellent** | The text is fully corrected: no detectable mistakes, perfect grammar, punctuation, and syntax. The result is fluent, natural, and faithful to the original content.             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1642b84-ff4c-4a6c-9726-3113eb8add59",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acb440-8475-4849-904f-9edf14a8e55c",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f2b60f-d5ab-430a-be25-a70f5fa6f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "extract_dir = os.path.expanduser(\"~/work/MNLP-project-2/data/eng\")\n",
    "\n",
    "clean_path = os.path.join(extract_dir, \"the_vampyre_clean.json\")\n",
    "\n",
    "with open(clean_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clean_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b4116d-8002-4193-b5da-7abd46fe7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_values_dict(d):\n",
    "    \"\"\"\n",
    "    Concat values of a dict, seperating each element with '\\n'\n",
    "\n",
    "    Args:\n",
    "        d (dict): Dictionnary\n",
    "\n",
    "    Returns:\n",
    "        str: concatenated text\n",
    "    \"\"\"\n",
    "    return '\\n'.join(d.get(str(i), \"\") for i in range(48))\n",
    "\n",
    "clean_data_text = concat_values_dict(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d5862-942d-4081-b214-a2329f5c1d0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a06c1f-b66e-4c0a-aefa-5a26d86fdfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>translated_fr_text</th>\n",
       "      <th>back_translated_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...</td>\n",
       "      <td>LE VAMPYRE;\\nUn conte.\\nPar John William Polid...</td>\n",
       "      <td>VAMPYRE;\\nA tale.\\nBy John William Polidori\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy Johri William Polido...</td>\n",
       "      <td>LE VAMPYRE;\\nUn conte.\\nPar Johri William Poli...</td>\n",
       "      <td>VAMPYRE;\\nA tale.\\nBy Johri William Polidori\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...</td>\n",
       "      <td>LE VAMPYRE;\\nUn conte.\\nPar John William Polid...</td>\n",
       "      <td>VAMPYRE;\\nA tale.\\nBy John William Polidori\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John Wjlliam Polidor...</td>\n",
       "      <td>LE VAMPYRE;\\nUn conte.\\nPar John Wjlliam Polid...</td>\n",
       "      <td>VAMPYRE;\\nA tale.\\nBy John Wjlliam Polidori\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy Jahn William PoIjdor...</td>\n",
       "      <td>LE VAMPYRE;\\nUn conte.\\nPar Jahn William PoIjd...</td>\n",
       "      <td>VAMPYRE;\\nA tale.\\nBy Jahn William PoIjdori\\nT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           original_text  \\\n",
       "index                                                      \n",
       "0      THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...   \n",
       "1      THE VAMPYRE;\\nA Tale.\\nBy Johri William Polido...   \n",
       "2      THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...   \n",
       "3      THE VAMPYRE;\\nA Tale.\\nBy John Wjlliam Polidor...   \n",
       "4      THE VAMPYRE;\\nA Tale.\\nBy Jahn William PoIjdor...   \n",
       "\n",
       "                                      translated_fr_text  \\\n",
       "index                                                      \n",
       "0      LE VAMPYRE;\\nUn conte.\\nPar John William Polid...   \n",
       "1      LE VAMPYRE;\\nUn conte.\\nPar Johri William Poli...   \n",
       "2      LE VAMPYRE;\\nUn conte.\\nPar John William Polid...   \n",
       "3      LE VAMPYRE;\\nUn conte.\\nPar John Wjlliam Polid...   \n",
       "4      LE VAMPYRE;\\nUn conte.\\nPar Jahn William PoIjd...   \n",
       "\n",
       "                                    back_translated_text  \n",
       "index                                                     \n",
       "0      VAMPYRE;\\nA tale.\\nBy John William Polidori\\nT...  \n",
       "1      VAMPYRE;\\nA tale.\\nBy Johri William Polidori\\n...  \n",
       "2      VAMPYRE;\\nA tale.\\nBy John William Polidori\\nT...  \n",
       "3      VAMPYRE;\\nA tale.\\nBy John Wjlliam Polidori\\nT...  \n",
       "4      VAMPYRE;\\nA tale.\\nBy Jahn William PoIjdori\\nT...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "back_translation_correction = pd.read_csv('back_translation_correction.csv', index_col=0)\n",
    "back_translation_correction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ea517-aefa-41ba-9f3a-0711867763d0",
   "metadata": {},
   "source": [
    "We can not put all the translations in the LLM as a judge, so we build some batches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7657274d-e368-409a-a850-188c5e973b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille des batches\n",
    "batch_size = 1\n",
    "\n",
    "# Diviser le DataFrame en batches\n",
    "batches = [back_translation_correction[i:i + batch_size] for i in range(0, len(back_translation_correction), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842b97f1-7458-4040-9b43-30bf32a0e6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>translated_fr_text</th>\n",
       "      <th>back_translated_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...</td>\n",
       "      <td>LE VAMPYRE;\\nUn conte.\\nPar John William Polid...</td>\n",
       "      <td>VAMPYRE;\\nA tale.\\nBy John William Polidori\\nT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           original_text  \\\n",
       "index                                                      \n",
       "0      THE VAMPYRE;\\nA Tale.\\nBy John William Polidor...   \n",
       "\n",
       "                                      translated_fr_text  \\\n",
       "index                                                      \n",
       "0      LE VAMPYRE;\\nUn conte.\\nPar John William Polid...   \n",
       "\n",
       "                                    back_translated_text  \n",
       "index                                                     \n",
       "0      VAMPYRE;\\nA tale.\\nBy John William Polidori\\nT...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71cd72ce-3528-458f-a79f-088053bac1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61452"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches[0]['back_translated_text'].to_list()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e63b98-8d06-4780-b124-cd0f1e873b33",
   "metadata": {},
   "source": [
    "# Evaluation thanks to LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae8ec6-6124-47dd-abda-90195b708066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1 / 48...\n",
      "Waiting 60 seconds before next text...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from google.generativeai import GenerativeModel\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Build the model Gemini (we take a small model not to be limited by the API)\n",
    "genai.configure(api_key=\"\")\n",
    "model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "\n",
    "# Function that divides text into chunks (we can not give the whole text as input => it's too big)\n",
    "def chunk_text(text, max_chunk_size=5000):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + max_chunk_size\n",
    "        if end < len(text):\n",
    "            last_space = text.rfind(\" \", start, end)\n",
    "            if last_space != -1 and last_space > start:\n",
    "                end = last_space\n",
    "        chunks.append(text[start:end].strip())\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "# Build the prompt\n",
    "def build_prompt_score_only(chunk):\n",
    "    return f\"\"\"You are a text quality evaluator. Evaluate the following corrected OCR text based on the detailed criteria below:\n",
    "\n",
    "1 - Very Poor: The text remains largely unreadable. Numerous errors persist (spelling, grammar, punctuation). The overall meaning is lost or extremely unclear. Little to no improvement made.\n",
    "2 - Poor: Slightly more readable than the original, but many errors remain. Several sentences are incorrect or ambiguous. Words are still distorted or missing.\n",
    "3 - Fair: Most obvious errors have been corrected. The text is generally understandable, but noticeable mistakes and awkward phrasing remain. The flow may be choppy.\n",
    "4 - Good: The text is readable and coherent. Only minor errors remain. There’s overall consistency, though a few syntax or word choice issues may still be present.\n",
    "5 - Excellent: The text is fully corrected: no detectable mistakes, perfect grammar, punctuation, and syntax. The result is fluent, natural, and faithful to the original content.\n",
    "\n",
    "Give only the numeric score (1 to 5). No explanation.\n",
    "\n",
    "Corrected Text:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\"\"\"\n",
    "\n",
    "# Function that return the evaluation score for every chunks in a text\n",
    "def evaluate_text(text):\n",
    "    chunks = chunk_text(text, max_chunk_size=5000)\n",
    "    scores_for_text = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        prompt = build_prompt_score_only(chunk)\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            raw_text = response.candidates[0].content.parts[0].text.strip()\n",
    "            if raw_text in {\"1\", \"2\", \"3\", \"4\", \"5\"}:\n",
    "                score = int(raw_text)\n",
    "            else:\n",
    "                score = -1\n",
    "        except Exception as e:\n",
    "            print(f\"Error on chunk {i}: {e}\")\n",
    "            score = -1\n",
    "\n",
    "        scores_for_text.append(score)\n",
    "    return scores_for_text\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(\"back_translation_correction.csv\")\n",
    "    all_scores = {}\n",
    "\n",
    "    for text_index in range(len(df)):\n",
    "        print(f\"Processing text {text_index + 1} / {len(df)}...\")\n",
    "        text = df.loc[text_index, \"back_translated_text\"]\n",
    "\n",
    "        scores = evaluate_text(text)\n",
    "        all_scores[text_index] = scores\n",
    "\n",
    "        # 1 minute break because of the API\n",
    "        if text_index < len(df) - 1:\n",
    "            print(\"Waiting 60 seconds before next text...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    rows = []\n",
    "    for text_index, scores_list in all_scores.items():\n",
    "        for chunk_index, score in enumerate(scores_list):\n",
    "            rows.append({\n",
    "                \"text_index\": text_index,\n",
    "                \"chunk_index\": chunk_index,\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "    df_scores = pd.DataFrame(rows)\n",
    "    df_scores.to_csv(\"Back_translation_gemini_scores_all_texts.csv\", index=False)\n",
    "    print(\"Over : Look at your new CSV files :) \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
